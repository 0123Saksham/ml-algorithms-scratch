# Machine Learning Algorithms from Scratch

This repository provides clean, well-documented implementations of foundational machine learning algorithms in Python. Each algorithm is built from first principles, with no reliance on high-level ML libraries, to foster a deep understanding of their mechanics.

## Repository Structure

```
Code/
  q1/  # Linear Regression (Gradient Descent)
    Q1.py
    linearX.csv
    linearY.csv
    grad_desc.jpg
    Hypothesis.png
  q2/  # Polynomial Regression
    Q2.py
  q3/  # Logistic Regression
    Q3.py
    logisticX.csv
    logisticY.csv
  q4/  # Gaussian Discriminant Analysis
    Q4.py
    q4x.dat
    q4y.dat
```

## Implemented Algorithms

- **Linear Regression (Gradient Descent):**  
  Implements linear regression using gradient descent optimization. Includes visualizations of the hypothesis and gradient descent process.

- **Polynomial Regression:**  
  Extends linear regression to model non-linear relationships using polynomial features.

- **Logistic Regression:**  
  Implements binary classification using logistic regression and gradient descent.

- **Gaussian Discriminant Analysis (GDA):**  
  Implements GDA for classification tasks, including data preprocessing and model evaluation.

## Data

All datasets are included in the respective folders.  
- CSV and DAT files are used for training and evaluation.
- Visualizations (PNG, JPG) are generated by the scripts.

## Getting Started

### Prerequisites

- Python 3.x
- Recommended packages: `numpy`, `matplotlib`

### Installation

Install dependencies using pip:
```powershell
pip install numpy matplotlib
```

### Usage

Navigate to the relevant folder and run the desired script:
```powershell
cd Code\q1
python Q1.py
```
Repeat for other algorithms (`Q2.py`, `Q3.py`, `Q4.py`) in their respective folders.

## Output

- Model parameters and evaluation metrics are printed to the console.
- Visualizations are saved in the corresponding folders.

## Contributing

Contributions are welcome! Please open issues or submit pull requests for improvements, bug fixes, or new algorithms.

## Contact

For questions or collaboration, please contact Saksham Kumar at [Sakshamkumar0123@gmail.com]
